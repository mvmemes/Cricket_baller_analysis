{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9885b65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#angle code:\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import math\n",
    "\n",
    "# Function to calculate the angle between the baller and the ground\n",
    "def calculate_baller_angle(baller_point, ground_point):\n",
    "    # Calculate the vector between the baller and the ground\n",
    "    vector = (baller_point[0] - ground_point[0], baller_point[1] - ground_point[1])\n",
    "\n",
    "    # Calculate the angle in radians\n",
    "    angle_rad = math.atan2(vector[1], vector[0])\n",
    "\n",
    "    # Convert the angle to degrees\n",
    "    angle_deg = math.degrees(angle_rad)\n",
    "\n",
    "    return angle_deg\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "output_video_filename = 'output_video_with_skeleton.avi'\n",
    "\n",
    "# Create a VideoWriter object to write the video to file.\n",
    "video_writer = cv2.VideoWriter(output_video_filename, fourcc,10, cap.get(cv2.CAP_PROP_FPS), (frame.shape[1], frame.shape[0]))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "# Initialize variables to store key points\n",
    "baller_position = None\n",
    "ground_position = None\n",
    "\n",
    "# while cap.isOpened():\n",
    "#     ret, frame = cap.read()\n",
    "#     if not ret:\n",
    "#         break\n",
    "\n",
    "    # Convert the frame to RGB\n",
    "frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Perform pose estimation\n",
    "results = pose.process(frame_rgb)\n",
    "\n",
    "if results.pose_landmarks:\n",
    "    landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "        # Define the key points for the baller and the ground (you may need to adjust these indices)\n",
    "    baller_keypoint = (landmarks[mp_pose.PoseLandmark.RIGHT_HIP].x, landmarks[mp_pose.PoseLandmark.RIGHT_HIP].y)\n",
    "    ground_keypoint = (landmarks[mp_pose.PoseLandmark.LEFT_ANKLE].x, landmarks[mp_pose.PoseLandmark.LEFT_ANKLE].y)\n",
    "\n",
    "        # Calculate the angle between the baller and the ground\n",
    "    baller_ground_angle = calculate_baller_angle(baller_keypoint, ground_keypoint)\n",
    "\n",
    "        # Display the angle on the frame\n",
    "    cv2.putText(frame, f\"Baller-Ground Angle: {baller_ground_angle:.2f} degrees\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "        # Draw key points for visualization\n",
    "    mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "    # Display the frame with overlays\n",
    "cv2.imshow(\"Baller Angle Estimation\", frame)\n",
    "\n",
    "if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "    break\n",
    "    \n",
    "cv2.imshow(\"Pose estimation\",frame)\n",
    "if cv2.waitKey(delay) & 0xFF == ord(\"q\"):\n",
    "\n",
    "    cap.release()\n",
    "    output.write(frame)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# The angle between the baller and the ground is calculated using the following steps:\n",
    "\n",
    "# The vector between the baller and the ground is calculated. This is done by subtracting the x and y coordinates of the ground point from the x and y coordinates of the baller point.\n",
    "# The angle in radians between the vector and the positive x-axis is calculated using the math.atan2() function. This function takes two arguments: the y-component of the vector and the x-component of the vector.\n",
    "# The angle in radians is converted to degrees using the math.degrees() function.\n",
    "# The resulting angle is the angle between the baller and the ground.\n",
    "\n",
    "# In mathematical terms, the angle is calculated as follows:\n",
    "\n",
    "# angle_rad = math.atan2(vector[1], vector[0])\n",
    "# angle_deg = math.degrees(angle_rad)\n",
    "# where:\n",
    "\n",
    "# vector[0] is the x-component of the vector between the baller and the ground\n",
    "# vector[1] is the y-component of the vector between the baller and the ground\n",
    "# The atan2() function returns the angle between the vector and the positive x-axis, in radians. The degrees() function converts the angle from radians to degrees.\n",
    "\n",
    "# For example, if the vector between the baller and the ground is (10, -5), then the angle between the baller and the ground would be calculated as follows:\n",
    "\n",
    "# angle_rad = math.atan2(-5, 10)\n",
    "# angle_deg = math.degrees(angle_rad)\n",
    "# The value of angle_rad would be approximately -0.4636476090008061, and the value of angle_deg would be approximately -26.56505117707798.\n",
    "\n",
    "# Therefore, the angle between the baller and the ground would be approximately 26.57 degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5289402a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(a, b, c):\n",
    "    # Calculate the angle between vectors AB and BC\n",
    "    angle_rad = math.atan2(c.y - b.y, c.x - b.x) - math.atan2(a.y - b.y, a.x - b.x)\n",
    "    angle_deg = math.degrees(angle_rad)\n",
    "    return angle_deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d37bf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate wrist movement (moment)\n",
    "def calculate_wrist_movement(prev_wrist, current_wrist):\n",
    "    if prev_wrist is None:\n",
    "        return 0.0\n",
    "    else:\n",
    "        # Calculate the Euclidean distance between previous and current wrist positions\n",
    "        return math.sqrt((prev_wrist.x - current_wrist.x) ** 2 + (prev_wrist.y - current_wrist.y) ** 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b24666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import math\n",
    "\n",
    "# Initialize the Pose Estimation model from Mediapipe\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# Open the video file for reading\n",
    "cap = cv2.VideoCapture(r\"C:\\Users\\MANSI\\Documents\\baller.mp4\")\n",
    "\n",
    "# Previous wrist positions for tracking movement\n",
    "prev_left_wrist = None\n",
    "prev_right_wrist = None\n",
    "\n",
    "# Main loop to process the video frames\n",
    "while cap.isOpened():\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Check if the video frame was successfully read\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to RGB format (MediaPipe requires RGB images)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame with the Pose Estimation model\n",
    "    results = pose.process(rgb_frame)\n",
    "\n",
    "    # Check if pose landmarks are detected in the frame\n",
    "    if results.pose_landmarks:\n",
    "        # Access the relevant keypoints (e.g., shoulders, elbows, wrists)\n",
    "        left_shoulder = results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER]\n",
    "        left_elbow = results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_ELBOW]\n",
    "        left_wrist = results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_WRIST]\n",
    "\n",
    "        right_shoulder = results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER]\n",
    "        right_elbow = results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_ELBOW]\n",
    "        right_wrist = results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_WRIST]\n",
    "\n",
    "        # Calculate the angles between the arms/hands\n",
    "        angle_left_arm = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "        angle_right_arm = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "\n",
    "        # Calculate the angles for the shoulders\n",
    "        angle_left_shoulder = calculate_angle(left_elbow, left_shoulder, right_shoulder)\n",
    "        angle_right_shoulder = calculate_angle(right_elbow, right_shoulder, left_shoulder)\n",
    "\n",
    "        # Calculate wrist movement (moment)\n",
    "        wrist_movement_left = calculate_wrist_movement(prev_left_wrist, left_wrist)\n",
    "        wrist_movement_right = calculate_wrist_movement(prev_right_wrist, right_wrist)\n",
    "\n",
    "        # Display the angles and wrist movement on the frame\n",
    "        cv2.putText(frame, f'Left Arm Angle: {angle_left_arm:.2f}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        cv2.putText(frame, f'Right Arm Angle: {angle_right_arm:.2f}', (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        cv2.putText(frame, f'Left Shoulder Angle: {angle_left_shoulder:.2f}', (10, 110), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        cv2.putText(frame, f'Right Shoulder Angle: {angle_right_shoulder:.2f}', (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        cv2.putText(frame, f'Left Wrist Movement: {wrist_movement_left:.2f}', (10, 190), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        cv2.putText(frame, f'Right Wrist Movement: {wrist_movement_right:.2f}', (10, 230), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "        # Update previous wrist positions\n",
    "        prev_left_wrist = left_wrist\n",
    "        prev_right_wrist = right_wrist\n",
    "\n",
    "    # Display the frame with annotations\n",
    "    cv2.imshow('Pose Estimation', frame)\n",
    "\n",
    "    # Break the loop if the 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release video resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8cbc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 visualization code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d0255c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected final \n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from scipy.interpolate import splprep, splev\n",
    "\n",
    "def visualize_loading_unloading(video_path, output_video_path, highlight_factor=0.02, zoom_factor=1.5, zoom_increment=0.005):\n",
    "    cap = cv2.VideoCapture(video_path)                                #cap is input object\n",
    "    mp_pose = mp.solutions.pose\n",
    "    pose = mp_pose.Pose()\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "#utilities\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "    prev_wrist_position = None\n",
    "    loading_started = False\n",
    "    highlight_intensity = 0.0\n",
    "    zoom_region = None\n",
    "    ball_track_points = []\n",
    "    ball_released = False\n",
    "    \n",
    "    manual_delay = int(1000/fps)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(frame_rgb)\n",
    "\n",
    "        if results.pose_landmarks is not None:\n",
    "            wrist_landmark = results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_WRIST]\n",
    "            wrist_x, wrist_y = int(wrist_landmark.x * frame.shape[1]), int(wrist_landmark.y * frame.shape[0])\n",
    "            \n",
    "            \n",
    "            # Extract shoulder, elbow, and wrist landmarks\n",
    "            left_shoulder_landmark = results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER]\n",
    "            left_elbow_landmark = results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_ELBOW]\n",
    "            left_wrist_landmark = results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_WRIST]\n",
    "\n",
    "            right_shoulder_landmark = results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER]\n",
    "            right_elbow_landmark = results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_ELBOW]\n",
    "            right_wrist_landmark = results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_WRIST]\n",
    "\n",
    "            # Convert landmarks to pixel coordinates\n",
    "            left_shoulder_x, left_shoulder_y = int(left_shoulder_landmark.x * frame.shape[1]), int(left_shoulder_landmark.y * frame.shape[0])\n",
    "            left_elbow_x, left_elbow_y = int(left_elbow_landmark.x * frame.shape[1]), int(left_elbow_landmark.y * frame.shape[0])\n",
    "            left_wrist_x, left_wrist_y = int(left_wrist_landmark.x * frame.shape[1]), int(left_wrist_landmark.y * frame.shape[0])\n",
    "\n",
    "            right_shoulder_x, right_shoulder_y = int(right_shoulder_landmark.x * frame.shape[1]), int(right_shoulder_landmark.y * frame.shape[0])\n",
    "            right_elbow_x, right_elbow_y = int(right_elbow_landmark.x * frame.shape[1]), int(right_elbow_landmark.y * frame.shape[0])\n",
    "            right_wrist_x, right_wrist_y = int(right_wrist_landmark.x * frame.shape[1]), int(right_wrist_landmark.y * frame.shape[0])\n",
    "\n",
    "            # Draw points at left shoulder, elbow, and wrist positions with blue color\n",
    "            cv2.circle(frame, (left_shoulder_x, left_shoulder_y), 5, (255, 0, 0), -1)\n",
    "            cv2.circle(frame, (left_elbow_x, left_elbow_y), 5, (255, 0, 0), -1)\n",
    "            cv2.circle(frame, (left_wrist_x, left_wrist_y), 5, (255, 0, 0), -1)\n",
    "\n",
    "            # Draw lines connecting left shoulder, elbow, and wrist with blue color\n",
    "            cv2.line(frame, (left_shoulder_x, left_shoulder_y), (left_elbow_x, left_elbow_y), (255, 0, 0), 2)\n",
    "            cv2.line(frame, (left_elbow_x, left_elbow_y), (left_wrist_x, left_wrist_y), (255, 0, 0), 2)\n",
    "\n",
    "            # Draw points at right shoulder, elbow, and wrist positions with red color\n",
    "            cv2.circle(frame, (right_shoulder_x, right_shoulder_y), 5, (0, 0, 255), -1)\n",
    "            cv2.circle(frame, (right_elbow_x, right_elbow_y), 5, (0, 0, 255), -1)\n",
    "            cv2.circle(frame, (right_wrist_x, right_wrist_y), 5, (0, 0, 255), -1)\n",
    "\n",
    "            # Draw lines connecting right shoulder, elbow, and wrist with red color\n",
    "            cv2.line(frame, (right_shoulder_x, right_shoulder_y), (right_elbow_x, right_elbow_y), (0, 0, 255), 2)\n",
    "            cv2.line(frame, (right_elbow_x, right_elbow_y), (right_wrist_x, right_wrist_y), (0, 0, 255), 2)\n",
    "\n",
    "            # Highlight code remains unchanged\n",
    "\n",
    "            left_wrist_x, left_wrist_y = int(left_wrist_landmark.x * frame.shape[1]), int(left_wrist_landmark.y * frame.shape[0])\n",
    "\n",
    "            if left_wrist_y < height / 2:\n",
    "                loading_started = True\n",
    "#                 cv2.putText(frame, \"Wrist Action: Release\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255),\n",
    "#                             2, cv2.LINE_AA)\n",
    "\n",
    "            elif left_wrist_y > height / 2 and loading_started:\n",
    "                cv2.putText(frame, \"Wrist Action: Grip\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255),\n",
    "                            2, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "            # Draw points at wrist positions\n",
    "            cv2.circle(frame, (wrist_x, wrist_y), 5, (255, 0, 0), -1)\n",
    "\n",
    "            # Draw trajectory line\n",
    "            if prev_wrist_position is not None:\n",
    "                cv2.line(frame, prev_wrist_position, (wrist_x, wrist_y), (0, 255, 0), 2)\n",
    "\n",
    "            prev_wrist_position = (wrist_x, wrist_y)\n",
    "\n",
    "            # Highlight code remains unchanged\n",
    "\n",
    "            if wrist_y < height / 2:\n",
    "                loading_started = True\n",
    "                cv2.putText(frame, \"Point : Unloading\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2,\n",
    "                            cv2.LINE_AA)\n",
    "\n",
    "                zoom_region = (max(0, wrist_x - 50), max(0, wrist_y - 50),\n",
    "                               min(width, wrist_x + 50), min(height, wrist_y + 50))\n",
    "\n",
    "                ball_track_points.append((wrist_x, wrist_y))\n",
    "\n",
    "                line_color = (0, 0, 255)\n",
    "\n",
    "                ball_released = False\n",
    "\n",
    "                cv2.putText(frame, \"Wrist Action: Release\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255),\n",
    "                            2, cv2.LINE_AA)\n",
    "\n",
    "            elif wrist_y > height / 2 and loading_started:\n",
    "                cv2.putText(frame, \"Point : Loading\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2,\n",
    "                            cv2.LINE_AA)\n",
    "\n",
    "                zoom_region = (max(0, wrist_x - 50), max(0, wrist_y - 50),\n",
    "                               min(width, wrist_x + 50), min(height, wrist_y + 50))\n",
    "\n",
    "                ball_track_points.append((wrist_x, wrist_y))\n",
    "\n",
    "                line_color = (255, 0, 0)\n",
    "\n",
    "                ball_released = True\n",
    "\n",
    "                if ball_released and len(ball_track_points) >= 3:\n",
    "                    # Interpolate points using quadratic Bézier curve\n",
    "                    interpolated_points = []\n",
    "                    for t in np.linspace(0, 1, 100):\n",
    "                        x = int((1 - t) ** 2 * ball_track_points[-3][0] + 2 * (1 - t) * t * ball_track_points[-2][0] + t ** 2 * ball_track_points[-1][0])\n",
    "                        y = int((1 - t) ** 2 * ball_track_points[-3][1] + 2 * (1 - t) * t * ball_track_points[-2][1] + t ** 2 * ball_track_points[-1][1])\n",
    "                        interpolated_points.append((x, y))\n",
    "\n",
    "                    # Draw the smooth curved line\n",
    "                    cv2.polylines(frame, [np.array(interpolated_points)], isClosed=False, color=line_color, thickness=2)\n",
    "\n",
    "            # Zoom-in effect remains unchanged\n",
    "\n",
    "        # Write the frame to the output video\n",
    "        out.write(frame)\n",
    "        cv2.imshow('Final', frame)\n",
    "        \n",
    "        key = cv2.waitKey(manual_delay) & 0xFF\n",
    "        \n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Specify the path to your input and output video files\n",
    "input_video_path = r'C:\\Users\\MANSI\\Documents\\b4.mp4'  # Replace with your input video file path\n",
    "output_video_path = r'C:\\Users\\MANSI\\Documents\\output_11.avi'  # Replace with your desired output video file path\n",
    "\n",
    "# Call the function to detect loading and unloading positions, highlight details, and save the output video\n",
    "visualize_loading_unloading(input_video_path, output_video_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7d5d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arms detection code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ccfdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final bassss\n",
    "#final bassss\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "def visualize_loading_unloading(video_path, output_video_path, highlight_factor=0.02, zoom_factor=1.5, zoom_increment=0.005):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    mp_pose = mp.solutions.pose\n",
    "    pose = mp_pose.Pose()\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "    prev_wrist_position = None\n",
    "    loading_started = False\n",
    "    highlight_intensity = 0.0\n",
    "    zoom_region = None\n",
    "    ball_track_points = []\n",
    "    ball_released = False\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(frame_rgb)\n",
    "\n",
    "        if results.pose_landmarks is not None:\n",
    "            # Extract shoulder, elbow, and wrist landmarks\n",
    "            shoulder_landmark = results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER]\n",
    "            elbow_landmark = results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_ELBOW]\n",
    "            wrist_landmark = results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_WRIST]\n",
    "\n",
    "            # Convert landmarks to pixel coordinates\n",
    "            shoulder_x, shoulder_y = int(shoulder_landmark.x * frame.shape[1]), int(shoulder_landmark.y * frame.shape[0])\n",
    "            elbow_x, elbow_y = int(elbow_landmark.x * frame.shape[1]), int(elbow_landmark.y * frame.shape[0])\n",
    "            wrist_x, wrist_y = int(wrist_landmark.x * frame.shape[1]), int(wrist_landmark.y * frame.shape[0])\n",
    "\n",
    "            # Draw points at shoulder, elbow, and wrist positions\n",
    "            cv2.circle(frame, (shoulder_x, shoulder_y), 5, (0, 255, 0), -1)\n",
    "            cv2.circle(frame, (elbow_x, elbow_y), 5, (0, 0, 255), -1)\n",
    "            cv2.circle(frame, (wrist_x, wrist_y), 5, (255, 0, 0), -1)\n",
    "\n",
    "            # Draw lines connecting shoulder, elbow, and wrist\n",
    "            cv2.line(frame, (shoulder_x, shoulder_y), (elbow_x, elbow_y), (0, 255, 0), 2)\n",
    "            cv2.line(frame, (elbow_x, elbow_y), (wrist_x, wrist_y), (0, 0, 255), 2)\n",
    "\n",
    "            # Highlight code remains unchanged\n",
    "\n",
    "            wrist_x, wrist_y = int(wrist_landmark.x * frame.shape[1]), int(wrist_landmark.y * frame.shape[0])\n",
    "\n",
    "            if wrist_y < height / 2:\n",
    "                loading_started = True\n",
    "                cv2.putText(frame, \"Point : Unloading\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2,\n",
    "                            cv2.LINE_AA)\n",
    "\n",
    "                cv2.rectangle(frame, (max(0, wrist_x - 50), max(0, wrist_y - 50)),\n",
    "                              (min(width, wrist_x + 50), min(height, wrist_y + 50)),\n",
    "                              (0, 0, 255), 2)\n",
    "\n",
    "                zoom_region = (max(0, wrist_x - 50), max(0, wrist_y - 50),\n",
    "                               min(width, wrist_x + 50), min(height, wrist_y + 50))\n",
    "\n",
    "                ball_track_points.append((wrist_x, wrist_y))\n",
    "\n",
    "                line_color = (0, 0, 255)\n",
    "\n",
    "                ball_released = False\n",
    "\n",
    "                cv2.putText(frame, \"Wrist Action: Release\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255),\n",
    "                            2, cv2.LINE_AA)\n",
    "\n",
    "            elif wrist_y > height / 2 and loading_started:\n",
    "                cv2.putText(frame, \"Point : Loading\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2,\n",
    "                            cv2.LINE_AA)\n",
    "\n",
    "                if not ball_released:\n",
    "                    cv2.rectangle(frame, (max(0, wrist_x - 50), max(0, wrist_y - 50)),\n",
    "                                  (min(width, wrist_x + 50), min(height, wrist_y + 50)),\n",
    "                                  (255, 0, 0), 2)\n",
    "\n",
    "                zoom_region = (max(0, wrist_x - 50), max(0, wrist_y - 50),\n",
    "                               min(width, wrist_x + 50), min(height, wrist_y + 50))\n",
    "\n",
    "                ball_track_points.append((wrist_x, wrist_y))\n",
    "\n",
    "                line_color = (255, 0, 0)\n",
    "\n",
    "                ball_released = True\n",
    "\n",
    "                if ball_released and len(ball_track_points) >= 3:\n",
    "                    # Interpolate points using quadratic Bézier curve\n",
    "                    interpolated_points = []\n",
    "                    for t in np.linspace(0, 1, 100):\n",
    "                        x = int((1 - t) ** 2 * ball_track_points[-3][0] + 2 * (1 - t) * t * ball_track_points[-2][0] + t ** 2 * ball_track_points[-1][0])\n",
    "                        y = int((1 - t) ** 2 * ball_track_points[-3][1] + 2 * (1 - t) * t * ball_track_points[-2][1] + t ** 2 * ball_track_points[-1][1])\n",
    "                        interpolated_points.append((x, y))\n",
    "\n",
    "                    # Draw the smooth curved line\n",
    "                    cv2.polylines(frame, [np.array(interpolated_points)], isClosed=False, color=line_color, thickness=2)\n",
    "\n",
    "                elbow_extension = np.linalg.norm(\n",
    "                    np.array([elbow_landmark.x, elbow_landmark.y]) - np.array([wrist_landmark.x, wrist_landmark.y]))\n",
    "\n",
    "                shoulder_rotation = np.degrees(\n",
    "                    np.arctan2(wrist_landmark.y - shoulder_landmark.y, wrist_landmark.x - shoulder_landmark.x))\n",
    "                cv2.putText(frame, f\"Shoulder Rotation: {round(shoulder_rotation, 2)}\", (10, 120),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "                cv2.putText(frame, \"Body Mechanics: Balanced Release\", (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.7,\n",
    "                            (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "                        # Zoom-in effect\n",
    "            if zoom_region is not None:\n",
    "                M = cv2.getRotationMatrix2D((wrist_x, wrist_y), 0, zoom_factor)\n",
    "                zoom_frame = cv2.warpAffine(frame, M, (width, height), flags=cv2.INTER_LINEAR,\n",
    "                                            borderMode=cv2.BORDER_CONSTANT, borderValue=(255, 255, 255))\n",
    "\n",
    "                # Combine the original frame and the zoomed frame within the specified region\n",
    "                frame[zoom_region[1]:zoom_region[3], zoom_region[0]:zoom_region[2]] = \\\n",
    "                    cv2.addWeighted(frame[zoom_region[1]:zoom_region[3], zoom_region[0]:zoom_region[2]],\n",
    "                                    1.0 - highlight_intensity,\n",
    "                                    zoom_frame[zoom_region[1]:zoom_region[3], zoom_region[0]:zoom_region[2]],\n",
    "                                    highlight_intensity, 0)\n",
    "\n",
    "            # Increment the zoom factor\n",
    "            zoom_factor += zoom_increment\n",
    "\n",
    "        # Write the frame to the output video\n",
    "        out.write(frame)\n",
    "        cv2.imshow('Final', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Specify the path to your input and output video files\n",
    "input_video_path = r'C:\\Users\\MANSI\\Documents\\abc.mp4'  # Replace with your input video file path\n",
    "output_video_path = r'C:\\Users\\MANSI\\Documents\\output_9.avi'  # Replace with your desired output video file path\n",
    "\n",
    "# Call the function to detect loading and unloading positions, highlight details, and save the output video\n",
    "visualize_loading_unloading(input_video_path, output_video_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a3bd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading and unloading detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0288fa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#magnify without skeleton:\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "def visualize_loading_unloading(video_path, output_video_path, highlight_factor=0.02, zoom_factor=1.5, zoom_increment=0.005):\n",
    "    # Create a VideoCapture object\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Create a Pose object from MediaPipe\n",
    "    mp_pose = mp.solutions.pose\n",
    "    pose = mp_pose.Pose()\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "    # Get video properties\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    # Define the codec and create a VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "    # Initialize variables\n",
    "    prev_wrist_position = None\n",
    "    loading_started = False\n",
    "    highlight_intensity = 0.0\n",
    "    zoom_region = None\n",
    "\n",
    "    while True:\n",
    "        # Read a frame from the video\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break  # Break the loop if we have reached the end of the video\n",
    "\n",
    "        # Convert the frame to RGB\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Process the frame with MediaPipe Pose\n",
    "        results = pose.process(frame_rgb)\n",
    "\n",
    "        # Check if keypoints are detected\n",
    "        if results.pose_landmarks is not None:\n",
    "            # Get the position of the right wrist landmark\n",
    "            wrist_landmark = results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_WRIST]\n",
    "            wrist_x, wrist_y = int(wrist_landmark.x * frame.shape[1]), int(wrist_landmark.y * frame.shape[0])\n",
    "\n",
    "            # Gradually increase the highlight intensity\n",
    "            highlight_intensity = min(1.0, highlight_intensity + highlight_factor)\n",
    "\n",
    "            # Determine loading phase based on wrist position\n",
    "            if wrist_y < height / 2:\n",
    "                loading_started = True\n",
    "\n",
    "                # Add a text message for loading\n",
    "                cv2.putText(frame, \"Point : Unloading\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "                # Draw a red border around the magnified region\n",
    "                cv2.rectangle(frame, (max(0, wrist_x - 50), max(0, wrist_y - 50)),\n",
    "                              (min(width, wrist_x + 50), min(height, wrist_y + 50)),\n",
    "                              (0, 0, 255), 2)\n",
    "\n",
    "                # Update zoom region\n",
    "                zoom_region = (max(0, wrist_x - 50), max(0, wrist_y - 50),\n",
    "                               min(width, wrist_x + 50), min(height, wrist_y + 50))\n",
    "\n",
    "            # Determine unloading phase based on wrist position and loading flag\n",
    "            elif wrist_y > height / 2 and loading_started:\n",
    "                # Add a text message for unloading\n",
    "                cv2.putText(frame, \"Point : Loading\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "                # Draw a blue border around the magnified region\n",
    "                cv2.rectangle(frame, (max(0, wrist_x - 50), max(0, wrist_y - 50)),\n",
    "                              (min(width, wrist_x + 50), min(height, wrist_y + 50)),\n",
    "                              (255, 0, 0), 2)\n",
    "\n",
    "                # Update zoom region\n",
    "                zoom_region = (max(0, wrist_x - 50), max(0, wrist_y - 50),\n",
    "                               min(width, wrist_x + 50), min(height, wrist_y + 50))\n",
    "\n",
    "            # Zoom-in effect\n",
    "            if zoom_region is not None:\n",
    "                M = cv2.getRotationMatrix2D((wrist_x, wrist_y), 0, zoom_factor)\n",
    "                zoom_frame = cv2.warpAffine(frame, M, (width, height), flags=cv2.INTER_LINEAR,\n",
    "                                            borderMode=cv2.BORDER_CONSTANT, borderValue=(255, 255, 255))\n",
    "\n",
    "                # Combine the original frame and the zoomed frame within the specified region\n",
    "                frame[zoom_region[1]:zoom_region[3], zoom_region[0]:zoom_region[2]] = \\\n",
    "                    cv2.addWeighted(frame[zoom_region[1]:zoom_region[3], zoom_region[0]:zoom_region[2]],\n",
    "                                    1.0 - highlight_intensity,\n",
    "                                    zoom_frame[zoom_region[1]:zoom_region[3], zoom_region[0]:zoom_region[2]],\n",
    "                                    highlight_intensity, 0)\n",
    "\n",
    "            # Increment the zoom factor\n",
    "            zoom_factor += zoom_increment\n",
    "\n",
    "        # Write the frame to the output video\n",
    "        out.write(frame)\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow('Final', frame)\n",
    "\n",
    "        # Exit the loop when 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the video capture and writer objects, and close all windows\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Specify the path to your input and output video files\n",
    "input_video_path = r'C:\\Users\\MANSI\\Documents\\new.mp4'  # Replace with your input video file path\n",
    "output_video_path = r'C:\\Users\\MANSI\\Documents\\output_h.avi'  # Replace with your desired output video file path\n",
    "\n",
    "# Call the function to detect loading and unloading positions, highlight details, and save the output video\n",
    "visualize_loading_unloading(input_video_path, output_video_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
